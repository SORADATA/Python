{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ff205da",
   "metadata": {},
   "source": [
    "# TP 1: Réduction de dimensionnalité\n",
    "\n",
    "\n",
    "Ce notebook est écrit à l'aide de l'environement Jupyter, qui permet de taper dans un même document des cellules de code, du texte au format markdown, et d'afficher les sorties Python dans le corps du document. Le désavantage par rapport à un environnement de code comme RStudio ou Spyder est l'absence d'un explorateur des variables. Ceci se corrige en lançant *Anaconda prompt* et en entrant les lignes suivantes:\n",
    "\n",
    "pip install jupyter_contrib_nbextensions\n",
    "\n",
    "jupyter contrib nbextension install --user\n",
    "\n",
    "En relançant Jupyter, un onglet extensions est ajouté où vous pouvez choisir celles que vous souhaitez, notamment le *variable inspector*.\n",
    "\n",
    "\n",
    "\n",
    "## Partie 1: Analyse en composantes principales\n",
    "\n",
    "\n",
    "### 1.1 Préparation des données\n",
    "\n",
    "Dans cette partie, nous allons travailler sur la base de données Worldwide Governance Indicators que vous trouverez sur ARCHE.\n",
    "\n",
    "Commencez par télécharger le fichier de données wgidataset.dta ainsi que le fichier WGIReadme.pdf qui l'accompagne.\n",
    "\n",
    "A la lecture du *readme*, répondez aux questions suivantes:\n",
    "\n",
    "* 1) Quelle est la source des données? Est-ce une source fiable?\n",
    "* 2) Quelles sont les variables contenues dans la base? Sous quelle forme se présentent-elles?\n",
    "\n",
    "Nous allons importer les données dans Python à l'aide du package *pandas*. Comme la base est enregistrée en local, nous allons avoir également besoin du package *os* qui permet de naviguer dans les dossiers de votre ordinateur.\n",
    "\n",
    "Dans la cellule de code ci-dessous, importez les packages requis. Comme il est nécessaire d'écrire le nom complet d'un package à chaque fois qu'on utilise une de ses fonctions, il est fréquent de les renommer en les important. Importez *pandas* et nommez le *pd*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa28657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29385abd",
   "metadata": {},
   "source": [
    "Pour importer un fichier de données enregistré en local, il faut préciser à Python le chemin du dossier où se trouve le fichier. Vous le trouverez à l'aide de l'explorateur de fichiers ou dans les propriétés du fichier.\n",
    "\n",
    "Le package *os* permet de renseigner le chemin d'accès d'un dossier à l'aide de la fonction *chdir()*. Lorsqu'on utilise une fonction d'un package, il faut l'écrire au format package.fonction: ici *os.chdir*. \n",
    "\n",
    "Pour savoir quels sont les arguments de la fonction et leurs types, tapez \"os.chdir?\" dans la console ou dans une cellule Jupyter. Complétez ensuite le code ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4c0b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2ef643",
   "metadata": {},
   "source": [
    "Il existe de nombreux formats pour enregistrer une base de données: xls, xlsx, csv, txt, etc.\n",
    "\n",
    "La WGI est enregistrée au format .dta qui est celui utilisé par Stata.\n",
    "\n",
    "Pandas permet d'importer presque tous les formats de données en utilisant les fonctions dédiées: read_csv, read_excel, read_json, etc. Pour lire des données en .dta, nous allons utiliser la fonction *read_stata*. Dans la cellule ci-dessous, importez la base dans une variable appelée *data_raw*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6b792e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw=pd.read_stata()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f490ea1d",
   "metadata": {},
   "source": [
    "Pour voir l'allure des données ou obtenir des statistiques descriptives, *pandas* propose de nombreuses fonctions utiles:\n",
    "\n",
    "* count: compte le nombre de données renseignées par variable\n",
    "* head: affiche les premières lignes de la base\n",
    "* info: donne le nombre de données renseignées et le type de chaque variable\n",
    "* describe: donne des statistiques descriptives sur chaque variable\n",
    "* mean: donne la moyenne de chaque variable\n",
    "\n",
    "Utilisez ces fonctions pour explorer la base et répondez aux questions suivantes:\n",
    "\n",
    "* 3) Combien y a-t-il de données manquantes pour la variable 'pve'?\n",
    "* 4) Y a-t-il de potentiels outliers? Quel traitement préalable devons-nous appliquer aux données?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21af83a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5756944",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccad9aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715f3af9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93111779",
   "metadata": {},
   "source": [
    "La plupart des variables de la base ne nous intéressent pas directement. A partir du fichier *readme*, sélectionnez les principaux indicateurs.\n",
    "\n",
    "Plutôt que de retirer les variables inutiles de la base, il est préférable de créer une nouvelle base en ne gardant que les variables qui nous intéressent. Créez une nouvelle base intitulée *data* contenant les variables sélectionnées.\n",
    "\n",
    "Vérifiez que la base *data* contient bien les données souhaitées à l'aide de la fonction *head*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e73a261",
   "metadata": {},
   "outputs": [],
   "source": [
    "data="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529536b8",
   "metadata": {},
   "source": [
    "La base contient des données de panel, observées par pays et par année. On peut ainsi voir l'évolution des indicateurs au cours du temps. Choisissez un pays et créez une nouvelle base *df_pays* contenant les données de ce seul pays.\n",
    "\n",
    "Il y a trois méthodes pour le faire:\n",
    "* data[(data.countryname=='France')]\n",
    "* data.loc[(data.countryname=='France')]\n",
    "* data.query('countryname'=='France')\n",
    "\n",
    "Toutes produisent le même résultat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0570506a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pays="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcdcf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pays.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bc5692",
   "metadata": {},
   "source": [
    "Pour visualiser l'évolution des indicateurs au cours de la période 1996-2022, on souhaite tracer un graphique. Pour cela, nous avons besoin de la fonction *pyplot* du package *matplotlib*. On importe une fonction donnée avec la syntaxe PACKAGE.FONCTION\n",
    "\n",
    "Dans la cellule ci-dessous, importez *pyplot* et renommez-la \"plt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362d0fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4f39c4",
   "metadata": {},
   "source": [
    "Pour réaliser une graphique d'un des indicateurs, on utilise la fonction *plot*. Lisez l'aide de la fonction puis tracez un indicateur en fonction de l'année dans la cellule ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2660373d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c417050f",
   "metadata": {},
   "source": [
    "Dans Jupyter, les graphiques s'affichent automatiquement sous la cellule mais en général, il faut préciser à Python de le faire avec la commande *plt.show()*.\n",
    "\n",
    "On peut essayer de rendre le graphique un peu plus élégant, en ajoutant par exemple des noms aux axes, en changeant la couleur de la courbe, etc. On peut également faire figurer sur le même graphe plusieurs séries en les renseignant les unes à la suite des autres dans la fonction *plot* sous la forme *x,y,couleur,label*. Par exemple plt.plot(x, y1, 'b', label='y1, x, y2, 'g', label='y2') affichera y1 en fonction de x en bleu et y2 en fonction de x en vert. \n",
    "\n",
    "Lorsqu'on met une légende, il faut demander à Python de la faire figurer avec la fonction *legend*.\n",
    "\n",
    "\n",
    "Si on veut représenter beaucoup de variables, cette syntaxe n'est pas pratique. Plus simplement, on peut utiliser plusieurs fois la fonction *plot* successivement.\n",
    "\n",
    "On peut également ajouter un titre avec la fonction *title*.\n",
    "\n",
    "\n",
    "Dans la cellule ci-dessous, tracez trois indicateurs de votre choix dans des couleurs différentes, ajoutez un titre, légendez les courbes et ajoutez une légende à l'axe des abscisses avec la fonction *xlabel*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e39bac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68242371",
   "metadata": {},
   "source": [
    "* 5) Commentez brièvement le graphique obtenu.\n",
    "\n",
    "On revient désormais à la base de données *data*. Pour analyser les liens entre les variables, on se propose d'utiliser l'analyse en composantes principales. Avant de pouvoir le faire, il va falloir filtrer un peu plus les données.\n",
    "\n",
    "* 6) Quels types de données peuvent être traités par une ACP? Quelles variables faut-il retirer?\n",
    "\n",
    "* 7) Dans la structure des données, qu'est-ce qui peut perturber le calcul d'une ACP? Comment filtrer les données correctement?\n",
    "\n",
    "En Python, la plupart des objets (vecteurs, bases, listes, etc) disposent de fonctions précodées appelées \"méthodes\". On les utilise via la syntaxe OBJET.METHODE. Par exemple, pour retirer des colonnes à une base de données nommée *data*, on écrit data.drop([], axis=1) en renseignant dans les crochets les colonnes à retirer. L'argument \"axis=1\" signifie qu'on supprime des colonnes. Pour supprimer des lignes, on écrirait \"axis=0\".\n",
    "\n",
    "Dans la cellule ci-dessous, créez une nouvelle base de données *df_acp* en filtrant la base *data* selon votre réponse à la question 7, puis retirez les colonnes identifiées à la question 6 à l'aide de la méthode *drop*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cd3ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acp="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ed462f",
   "metadata": {},
   "source": [
    "Une dernière chose à faire: vérifier qu'il n'y a pas de données manquantes. Vérifiez si c'est bien le cas dans la cellule ci-dessous et, au besoin, retirer les observations incomplètes en appliquant à la base *df_acp* la méthode *dropna()*. Pour s'épargner du temps, on peut aussi utiliser *dropna()* préventivement: s'il n'y a pas de données manquantes, ça ne changera pas la base. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b4e52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acp="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346d3260",
   "metadata": {},
   "source": [
    "### 1.2 Calcul de l'ACP\n",
    "\n",
    "\n",
    "Nous sommes désormais prêts à calculer une ACP sur la base *df_acp*. Le calcul nécessite d'utiliser plusieurs sous-fonctions du package *sklearn*. Nous aurons besoin de la sous-fonction PCA contenue dans la fonction *decomposition* et de la sous-fonction scale contenue dans la fonction *preprocessing* si jamais on souhaite centrer et réduire les variables. Il nous faudra aussi le package *numpy*, renommé np, qui permet de faire des calculs matriciels. Nous allons importer au passage le package *seaborn* en le renommant sb qui nous permettra de réaliser des sorties graphiques de meilleure qualité. \n",
    "\n",
    "* 8) Avons-nous besoin de centrer et réduire les données?\n",
    "\n",
    "Dans la cellule ci-dessous, importez les fonctions nécessaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee10953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sb\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca928d6c",
   "metadata": {},
   "source": [
    "*Seaborn* permet d'obtenir des rendus graphiques plus propres que *matplotlib* et dispose de fonctions utiles. La fonction pairplot permet d'obtenir la matrice des scatterplots pour chaque paire de variables. Essayez-la dans la cellule ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8118e07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00eb73ff",
   "metadata": {},
   "source": [
    "* 9) Que remarquez-vous sur le graphique? \n",
    "\n",
    "Pour vérifier, nous pouvons calculer la matrice des coefficients de corrélation de Pearson d'une base à l'aide de la méthode *corr*. Dans la cellule ci-dessous, appliquez la méthode *corr* à la base *df_acp*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabd4206",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19dc28a6",
   "metadata": {},
   "source": [
    "Pour mieux visualiser, on peut utiliser la fonction heatmap de *seaborn*, qui permet de colorier les entrées d'une matrice avec une coleur dépendant de leur valeur. Dans la cellule ci-dessous, tracez une heatmap du vecteur des corrélations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5789bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.heatmap()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c1ea0b",
   "metadata": {},
   "source": [
    "Pas mal, mais ce n'est pas très clair car l'échelle est ajusté aux valeurs observées. Refaites le même graphe mais en précisant dans la fonction heatmap les arguments suivants: vmin=-1, annot=True\n",
    "\n",
    "Cela indique à Seaborn que la valeur minimale de la série est -1 et lui demande de renseigner la valeur de chaque entrée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3972783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.heatmap()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1f54f5",
   "metadata": {},
   "source": [
    "* 10) Au vu de ce graphique, à quoi pouvons-nous nous attendre dans les résultats de l'ACP?\n",
    "\n",
    "\n",
    "Nous pouvons passer au calcul de l'ACP. En utilisant ScikitLearn, celui-ci se fait en deux étapes:\n",
    "* On définit une variable qui va contenir le modèle à estimer avec la fonction sklearn adéquate, ici PCA(). Lors de cette étape, on peut renseigner divers arguments dans la fonction PCA, par exemple le nombre d'axes à garder en entrant comme argument n_components=X. Si on ne renseigne rien, la fonction utilise les arguments par défaut qui sont précisés dans la documentation du package.\n",
    "\n",
    "* On ajuste le modèle sur une base de données via la méthode *fit* en précisant la base à utiliser en argument.\n",
    "\n",
    "Dans la cellule ci-dessous, créez une variable *pca* contenant le modèle de l'ACP avec la fonction PCA() puis estimez le modèle sur la base *df_acp*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c332f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b7155a",
   "metadata": {},
   "source": [
    "Pas de message d'erreur, c'est bon signe! Python a calculé l'ACP sur les données qu'on lui a renseignées et a gardé le résultat dans la variable pca. On utilisera donc cette variable et les différentes méthodes qui lui sont liées pour obtenir les résultats de l'ACP. \n",
    "\n",
    "En premier lieu, on souhaite voir les valeurs propres qui ont été obtenues. Pour cela, il y a deux méthodes qu'on peut appliquer à la variable pca:\n",
    "* explained_variance_ nous donne le vecteur des valeurs propres classées par ordre décroissant\n",
    "* explained_variance_ratio_ nous donne la part d'inertie (décroissante) expliquée par chaque axe\n",
    "\n",
    "Affichez ces deux vecteurs à l'aide de la fonction *print()*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180f1652",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9760d5ec",
   "metadata": {},
   "source": [
    "* 11) Quelle est l'inertie totale du nuage de points? D'après le critère de Kaiser, combien d'axes devrions nous garder?\n",
    "\n",
    "La fonction *cumsum* du package *numpy* permet d'obtenir les valeurs cumulatives croissantes d'un vecteur. Créez un vecteur exp_var_cumul contenant l'inertie cumulée expliquée par les axes de l'ACP et affichez ce vecteur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fcdcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_var_cumul = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9665f3ee",
   "metadata": {},
   "source": [
    "Pour compléter ce qu'indique le critère de Kaiser, on souhaite utiliser le critère du coude. Créez un graphique affichant l'éboulis des valeurs propres ou de la variance expliquée par chaque axe avec matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e13cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c0db2b",
   "metadata": {},
   "source": [
    "* 12) Selon le critère du coude, combien d'axes garderiez-vous? Quelle serait alors la part d'inertie expliquée?\n",
    "\n",
    "Une fois l'ACP calculée, on peut calculer les coordonnées des variable et des individus dans la nouvelle base. Pour cela, on crée une nouvelle basse de données *dft* en appliquant à l'objet acp la méthode *transform* et en précisant comme argument la base à transformer.\n",
    "\n",
    "Calculez ci-dessous la base transformée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282e2fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd331c2d",
   "metadata": {},
   "source": [
    "On peut également tout faire d'une seule ligne de commande avec la méthode *fit_transform*.\n",
    "\n",
    "La base *dft* contient les coordonnées des observations dans la base des composantes principales. ATTENTION: la méthode ne renvoit pas une base au format DataFrame de *pandas* mais un vecteur au format *numpy*.\n",
    "\n",
    "\n",
    "## 1.3 Interprétation des résultats\n",
    "\n",
    "On peut désormais s'intéresser à la construction des axes de l'ACP en traçant le cercle des corrélations. Il n'existe pas de code tout fait en Python pour cela, mais on peut facilement définire une fonction qui le fasse. La cellule ci-dessous contient une fonction *plot_correlation_circle* qui permet d'obtenir le cercle des corrélations pour des axes au choix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e97549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation_circle(axe1, axe2, data, label1, label2):    \n",
    "    fig, ax = plt.subplots(figsize=(16, 10))\n",
    "\n",
    "    for i in range(data.shape[1]):\n",
    "        x = np.corrcoef(axe1,data[data.columns[i]])[0,1]\n",
    "        y = np.corrcoef(axe2,data[data.columns[i]])[0,1]\n",
    "        ax.annotate(\"\", xy= (x,y), xytext=(0, 0),arrowprops=dict(arrowstyle=\"->\"))\n",
    "        ax.annotate(data.columns[i], (x+0.02,y+0.02), size=12)\n",
    "\n",
    "\n",
    "    ax.set_title('Cercle des corrélations')\n",
    "    ax.axhline(y=0, color=\"grey\", linestyle=\"--\")\n",
    "    ax.axvline(x=0, color=\"grey\", linestyle=\"--\")\n",
    "\n",
    "    an = np.linspace(0, 2 * np.pi, 100)\n",
    "    plt.plot(np.cos(an), np.sin(an))\n",
    "    plt.axis('equal')\n",
    "    plt.xlabel(str(label1))\n",
    "    plt.ylabel(str(label2))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268be08b",
   "metadata": {},
   "source": [
    "* 13) Commentez la fonction *plot_correlation_circle*: quels sont ses arguments, que calcule-t-elle, que renvoit-elle?\n",
    "\n",
    "Utilisez la fonction pour obtenir le cercle des corrélations pour les deux premiers axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b0966a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c5ced4d",
   "metadata": {},
   "source": [
    "* 14) Que constate-t-on sur le cercle des corrélations? Pouvait-on s'attendre à ce résultat?\n",
    "\n",
    "* 15) Interprétez les axes de l'ACP: quels types de pays opposent-ils?\n",
    "\n",
    "Après avoir interprété les axes, il est souhaitable de tracer le scatterplot des pays dans la nouvelle base pour voir s'il corrobore bien les interprétations proposées. Il y a toutefois un problème: les coordonnées des pays dans la nouvelle base sont contenues dans la base *dft* qui ne contient aucune information sur l'identité des observations.\n",
    "\n",
    "Pour essayer de la retrouver, il va falloir ruser un peu. Commencez par créer une base de données *dft_id* au format DataFrame à partir de la base *dft*. Pour cela, utilisez la fonction *DataFrame* de Pandas. Observez les indices des premières lignes de cette nouvelle base: quel est le problème?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c1d908",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft_id="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ea97c0",
   "metadata": {},
   "source": [
    "Heureusement, la base initiale *df_acp* est toujours disponible: gardez les bases de données intermédiaires!\n",
    "\n",
    "On peut retrouver pour chaque pays de *df_acp* le nom du pays auquel il correspond dans la base de données originale car les lignes ont gardé leurs indices d'origine! On va donc créer une nouvelle variable \"pays\" dans *dft_id* qui va aller chercher dans la base *data* le nom du pays correspondant à partir des indices de la base *df_acp*. Lors de l'ajout d'une nouvelle variable dans une base, Pandas match les données par indice, or les observations de *dft_id* ayant des indices différents de *data* et *df_acp*, il faut convertir la nouvelle variable en vecteur *numpy* avant de l'ajouter. Le code ci-dessous permet de le faire en une ligne, mais il est possible de le faire de bien d'autres façons. En Python, il 'y a pas de bonne ou mauvaise façon de faire, l'essentiel est que ça fonctionne! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a565e18",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "516690a4",
   "metadata": {},
   "source": [
    "Les noms des pays ont bien été récupérés correctement, nous pouvons donc créer un graphique pour représenter les différents pays dans le plan principal. Avant cela, renommez les deux premières colonnes de *dft_id* en 'dim1' et 'dim2' à l'aide de la méthode rename. Celle-ci prend pour argument columns= un dictionnaire contenant en clés les noms actuels des variables et en valeurs les nouveaux noms. Pour que les noms soient correctement changés dans la base sans avoir à en créer une nouvelle, il faut également précise l'argument inplace=True. \n",
    "\n",
    "Pour tracer le graphique, utilisez la fonction *plt.scatter()* en renseignant les bons arguments. Ajoutez un titre et un nom aux axes. Enfin, pour afficher les noms, il faut créer une boucle itérant sur les entrées de la base de données et qui, pour chaque itération, va écrire le nom du pays aux coordonnées du point. Les itérations se font donc sur des tuples du type $(dim1,dim2,nom)$. Pour faire une boucle sur des tuples, on utilise la commande zip() qui gère directement les valeurs à itérer. La syntaxe pour construire une boucle sera alors \"for i, j, nom in zip(dft_id['dim1'],dft_id['dim2'], dft_id['pays']):\"\n",
    "\n",
    "\n",
    "Pour écrire le nom des pays dans la boucle, utilisez la fonction *plt.text()* qui prend comme arguments l'abscisse, l'ordonnée et une chaîne de caractère à écrire au point renseigné (ici le nom du pays).\n",
    "\n",
    "\n",
    "Pour tracer des graphiques à partir d'une base de données au format DataFrame de Pandas, vous pouvez également utiliser la méthode *plot* associée aux objets *dataframes*, qui donne à peu près les mêmes résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45dde6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b601140",
   "metadata": {},
   "source": [
    "Ce n'est pas très lisible... Pour améliorer ça, nous pouvons:\n",
    "\n",
    "* augmenter la taille du graphique et sa résolution en la précisant en amont avec la commande plt.rcParams[\"figure.figsize\"] = [20, 15]\n",
    "* réduire la taille des annotations en précisant dans la commande plt.text l'argument fontsize=\n",
    "* annoter une partie des observations seulement en filtrant par une condition if --- : dans la boucle for \n",
    "\n",
    "Essayez dans la cellule ci-dessous d'obtenir une graphique de qualité satisfaisante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f125fb66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d5c9f4f",
   "metadata": {},
   "source": [
    "On voit sur le graphe que les pays d'un même continent sont regroupés assez proches les uns des autres. Il pourrait être judicieux de refaire le même graphe avec un code couleur par continent. Problème: cette information ne figure pas dans la base. Pour récupérer cette variable, plusieurs moyens existent:\n",
    "* utiliser chatGPT (attention aux erreurs!)\n",
    "* chercher des packages qui permettent de le faire\n",
    "\n",
    "Ce type de traitement de données peut prendre beaucoup de temps à régler, il ne faut donc pas hésiter à essayer les outils comme ChatGPT ou Bard qui peuvent trouver des solutions rapidement. La dernière version de ChatGPT peut lire des fichiers images, et donc traiter une base de données avec une simple capture d'écran. Attention toutefois: ce n'est pas un moteur de recherche mais un générateur de texte, les réponses proposées ne sont donc pas forcément vraies ou efficaces! \n",
    "\n",
    "Nous allons utiliser la deuxième option, mais elle est un peu complexe. Il est nécessaire d'utiliser le package *pycountry* qui permet de transformer des codes pays en codes continents.\n",
    "\n",
    "La difficulté dans notre base est que les noms des pays ne sont pas forcément identiques à ceux d'une autre base standard. Par exemple pour les Bahamas, le nom est \"Bahamas, The\". En joignant des bases, il est possible que le match ne soit pas détécté et que Python renvoit donc une erreur. Pour éviter cela, nous allons devoir retraiter traiter les noms de pays en amont. Une fois ceci fait, nous pouvons convertir les noms traités en codes ISO 3166-1 alpha-2 (norme internationale) et ensuite les matcher avec les continents correspondants. Certains packages permettaient de tout automatiser mais des conflits de versions les ont rendus inutilisables, il faut donc tout faire à la main! Beaucoup d'ennuis pour un simple graphique!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68111883",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pycountry_convert\n",
    "#!pip install pycountry\n",
    "import pycountry_convert as pc\n",
    "import pycountry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1df2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pays=dft_id['pays'].tolist()\n",
    "\n",
    "pays=list(map(lambda x: x.replace('Bahamas, The', 'Bahamas'), pays))\n",
    "pays=list(map(lambda x: x.replace('Congo, Rep.', 'Congo, The Democratic Republic of the'), pays))\n",
    "pays=list(map(lambda x: x.replace('Cape Verde', 'Cabo Verde'), pays))\n",
    "pays=list(map(lambda x: x.replace('Egypt, Arab Rep.', 'Egypt'), pays))\n",
    "pays=list(map(lambda x: x.replace('Micronesia, Fed. Sts.', 'Micronesia'), pays))\n",
    "pays=list(map(lambda x: x.replace('Gambia, The', 'Gambia'), pays))\n",
    "pays=list(map(lambda x: x.replace('Hong Kong SAR, China', 'Hong Kong'), pays))\n",
    "pays=list(map(lambda x: x.replace('Iran, Islamic Rep.', 'Iran'), pays))\n",
    "pays=list(map(lambda x: x.replace('Jersey, Channel Islands', 'Jersey'), pays))\n",
    "pays=list(map(lambda x: x.replace('St. Kitts and Nevis', 'nevis'), pays))\n",
    "pays=list(map(lambda x: x.replace('Korea, Rep.', 'South Korea'), pays))\n",
    "pays=list(map(lambda x: x.replace('Lao PDR', 'Lao'), pays))\n",
    "pays=list(map(lambda x: x.replace('Macao SAR, China', 'Macao'), pays))\n",
    "pays=list(map(lambda x: x.replace('St. Lucia', 'Saint Lucia'), pays))\n",
    "pays=list(map(lambda x: x.replace('Korea, Dem. Rep.', 'North Korea'), pays))\n",
    "pays=list(map(lambda x: x.replace('Türkiye', 'Turkey'), pays))\n",
    "pays=list(map(lambda x: x.replace('Taiwan, China', 'Taiwan'), pays))\n",
    "pays=list(map(lambda x: x.replace('St. Vincent and the Grenadines', 'Saint Vincent and the Grenadines'), pays))\n",
    "pays=list(map(lambda x: x.replace('Venezuela, RB', 'Venezuela'), pays))\n",
    "pays=list(map(lambda x: x.replace('West Bank and Gaza', 'Palestine, State of'), pays))\n",
    "pays=list(map(lambda x: x.replace('Yemen, Rep.', 'Yemen'), pays))\n",
    "pays=list(map(lambda x: x.replace('Congo, Dem. Rep.', 'Congo, The Democratic Republic of the'), pays))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pays_code=[]\n",
    "\n",
    "for i in pays:\n",
    "    match=pycountry.countries.search_fuzzy(i)\n",
    "    code=match[0].alpha_2\n",
    "    pays_code.append(code)\n",
    "\n",
    "\n",
    "pays_code=list(map(lambda x: x.replace('TL', 'CN'), pays_code))\n",
    "pays_code=list(map(lambda x: x.replace('UM', 'US'), pays_code))\n",
    "\n",
    "continent_name = [pc.country_alpha2_to_continent_code(i) for i in pays_code]\n",
    "\n",
    "dft_id['cont']=np.array(continent_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f06b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft_id.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a9d0c3",
   "metadata": {},
   "source": [
    "Succès! On peut maintenant obtenir le graphe désiré. Tous les packages graphiques peuvent être utilisés, toutefois certains sont plus simples que d'autres à mettre e oeuvre. Nous allons utiliser le package *plotly.express*. Ce package permet de réaliser des graphiques interactifs. La fonction *scatter* permet de colorier des points selon les valeurs d'une variable qualitative simplement. Le rendu est de bonne qualité et s'affiche directement dans un navigateur internet (si vous codez sur un IDE) ou dans le notebook si vous codez via Jupyter.\n",
    "\n",
    "Importez plotly.express et renommez le px, puis avec l'aide intégrée de Python et/ou une recherche sur votre moteur préféré, essayez de tracer le graphique souhaité. Pour adapter la taille des noms de pays, utilisez la méthode *update_traces(textfont_size=8)* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d46879c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import \n",
    "fig = px.scatter()\n",
    "fig.update_traces(textfont_size=8)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785a5b37",
   "metadata": {},
   "source": [
    "* 16) D'après les résultats de l'ACP, quelles analyses pouvez-vous faire du graphique ci-dessus?\n",
    "\n",
    "\n",
    "\n",
    "## 1.4 Analyse temporelle\n",
    "\n",
    "Il reste une dimension dans la base de données que nous n'exploitons pas: le temps. Chaque pays est observé annuellement et il peut être intéressant de voir comment cette évolution se retranscrit dans le plan de l'ACP. Pour cela, nous allons revenir à la base *data*, en faire une copie *data_pc* et calculer les coordonnées de toutes les observations dans le plan factoriel et les ajouter à *data_pc*. A partir des éléments vus dans le TP, essayez de le faire vous-mêmes et de résoudre les éventuels problèmes.\n",
    "\n",
    "\n",
    "Une fois la base *data_pc* construite, choisissez plusieurs pays aparaissant proches sur le graphique précédents et créez pour chacun une base contenant les observations de ce pays.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd44d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pc=\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6728c15",
   "metadata": {},
   "source": [
    "Une fois ces bases obtenues, il nous reste à construire un graphique rendant compte de l'évolution dans le temps de leurs coordonnées dans le plan factoriel. Pour cela, créez un graphe matplotlib traçant les coordonnées de chacun des pays choisis en utilisant une couleur différente par pays. Assurez-vous que chaque courbe possède un label et entrez la commande *plt.legend()* pour afficher une légende automatiquement.\n",
    "\n",
    "Pour que le graphique soit plus clair à lire, il est possible d'ajouter les années à côté de chaque point traçé, là encore avec une boucle *for* itérée sur les tuples $(dim1,dim2,year)$.\n",
    "\n",
    "Pour obtenir des effets visuels plus complexes, *matplotlib* inclut un sous-module *patheffects* qui offre de nombreuses options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aacd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19cf1e0",
   "metadata": {},
   "source": [
    "Le rendu de Matplotlib est correct mais pas très élégant et surtout peu lisible si on a beaucoup de pays à étudier. Pour des données temporelles, le package *plotly.express* permet d'obtenir des rendus animés de bien meilleure qualité. Pour cela, il suffit de préciser dans la fonction *px.scatter* une variable \"animation_frame=\" qui renseigne l'échelle de temps, et une variable \"animation_group=\" qui renseigne comment regrouper les données (ici, par pays)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9295fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a2fa1c",
   "metadata": {},
   "source": [
    "* 17: Quelles conclusions tirez vous de l'ACP? Quels modèles alternatifs utiliseriez-vous pour aller plus loin?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fef90eb",
   "metadata": {},
   "source": [
    "## Partie 2: Analyse des correspondances multiples\n",
    "\n",
    "### 2.1: Préparation des données\n",
    "\n",
    "Nous allons maintenant mettre en oeuvre l'analyse des correspondances multiples sur une base de données disponible sur [Kaggle](https://www.kaggle.com/datasets/mysarahmadbhat/lung-cancer) intitulée Lungcancer. Elle contient des réponses individuelles à un questionnaire qualitatif qui contient les informations suivantes:\n",
    "* Sexe du patient\n",
    "* Âge du patient\n",
    "* Fumeur?\n",
    "* Doigts jaunis\n",
    "* Anxiété ?\n",
    "* Stress ?\n",
    "* Présence d'une maladie chronique\n",
    "* Fatigue ?\n",
    "* Présence d'allergies \n",
    "* Obstructions respiratoires\n",
    "* Consommation d'alcool\n",
    "* Présence de toux chronique\n",
    "* Essouflement\n",
    "* Difficultés de déglutition\n",
    "* Présence de douleurs à la poitrine\n",
    "* Présence d'un cancer du poumon\n",
    "\n",
    "\n",
    "A l'exception de l'âge des patients, toutes ces variables sont qualitatives binaires. On se propose d'étudier la structure des corrélations entre modalités pour voir comment celles-ci ont un impact sur la potentielle présence d'un cancer du poumon.\n",
    "\n",
    "Pour commencer, importez le fichier de données \"survey lung cancer.csv\" avec la fonction *read_csv* de Pandas dans une base nommée *data_lc*. Au besoin, reprécisez le chemin d'accès avant via la fonction *os.chdir*. Vérifiez avec la méthode *head()* que le fichier a été correctement importé.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49309e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lc=pd.read_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23289efb",
   "metadata": {},
   "source": [
    "Avant de pouvoir calculer une ACM, il va falloir mettre au propre les données. Pour cela, nous allons devoir:\n",
    "* Requalifier les variables d'intérêt en variables qualitatives avec la fonction *pd.categorical()*\n",
    "* Renommer les modalités \"1\" et \"2\" en \"Non\" et \"Oui\" avec la méthode *cat.rename_categories()* \n",
    "* Transformer la variable \"AGE\" en variable qualitative avec la fonction *pd.qcut()* en la découpant en 3 classes d'âge.\n",
    "\n",
    "En utilisant l'aide intégrée sur chacune de ces commandes, effectuez le prétraitement des données dans la cellule ci-dessous. Vous pouvez faire une boucle itérant sur les colonnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f12c6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data_lc.columns:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61adefe3",
   "metadata": {},
   "source": [
    "Avant d'entammer les analyses, on peut effectuer quelques analyses descriptives. Par exemple, tracez un histogramme comparé de l'âge des répondants selon qu'ils aient un cancer du poumon ou non. Pour cela, utilisez la fonction *histplot* de Seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a4f2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.histplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ddf906",
   "metadata": {},
   "source": [
    "* 18: Quelle interprétation pouvez-vous faire du graphique précédent?\n",
    "\n",
    "### 2.2: Calcul de l'ACM\n",
    "\n",
    "Pour calculer une ACM, nous allons utiliser le package *mca* car ScikitLearn ne contient pas de fonctions le faisant naturellement. Installez le package via la commande \"!pip install mca\" si besoin, puis importez la fonction MCA de ce package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96568da6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "691a8ad7",
   "metadata": {},
   "source": [
    "Pour pouvoir estimer l'ACM, il faut construire le tableau disjonctif complet. Pour cela, créez une base *data_q* ne contenant que des données qualitatives. Ensuite, lisez la documentation de la fonction *pd.get_dummies*.\n",
    "\n",
    "Cette fonction prend en entrée une base de données et renvoit un vecteur numpy. Pour transformer ce dernier en base au format DataFrame, il faut utiliser la fonction *pd.DataFrame*.\n",
    "\n",
    "Construisez le tableau disjonctif complet en le nommant *tdc* et vérifiez qu'il contient bien les données souhaitées avec la méthode *head()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc454e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a865a77",
   "metadata": {},
   "source": [
    "Nous pouvons désormais calculer l'ACM en appliquant à la base *tdc* la fonction *MCA*. En utilisant l'aide intégrée si besoin, calculez l'acm dans une variable appelée mca_lc, en précisant l'option \"benzecri=False\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09af43f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89b7e58f",
   "metadata": {},
   "source": [
    "Le module MCA diffère un peu de l'ACP: chaque package fonctionne différemment, même si les méthodes sont identiques. Pour obtenir les résultats, on utilise les commandes suivantes:\n",
    "* mca_lc.L permet d'obtenir les valeurs propres\n",
    "* mca_lc.fs_c() permet d'obtenir les coordonnées des modalités\n",
    "* mca_lc.fs_r() permet d'obtenir les coordonées des individus\n",
    "\n",
    "Tous les résultats sont au format numpy. Une documentation complète figure [ici](https://github.com/esafak/mca/blob/master/docs/usage.rst). Dans la cellule ci-dessous, affichez les valeurs propres et tracez le graphique d'éboulis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f8dcda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5b81aa3",
   "metadata": {},
   "source": [
    "* 19: quelle interprétation faites-vous du graphique précédent? Y a-t-il une forte structure dans les données?\n",
    "\n",
    "### 2.3: Interprétation et visualisation des résultats\n",
    "\n",
    "Nous allons nous concentrer sur les deux premiers axes principaux et tracer les modalités dans ce plan. Tracez un scatterplot à l'aide du package de votre choix en y faisant figurer le nom des modalités."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277f8a7b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.scatter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76bfc5a",
   "metadata": {},
   "source": [
    "* 20: A partir du graphique précédent, quelle interprétation faites-vous des axes de l'ACM? Sont ils informatifs pour comprendre les déterminants du cancer du poumon?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
